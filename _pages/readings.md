---
layout: page
title: Readings
permalink: readings
show-title: false
---

## Upcoming Readings

* 10/8/2025
 Courtney C. Radsch, "[Panopticons and Closing Civic Space: The Building Blocks of Digital Authoritarianism](https://posada.website/publication/platform-authority-and-data-quality/Digital-Authoritarnism.pdf)" in [Decoding Digital Authoritarianism](https://posada.website/publication/platform-authority-and-data-quality/Digital-Authoritarnism.pdf), pp. 39-46
* 9/24/2025
  * Craig Spensr, "[The Trump Administration Will Automate Health Inequities](https://www.theatlantic.com/health/archive/2025/08/ai-health-inequities/684047/)"

## Past Readings

* 9/10/2025
  * Miriam Posner, "[What’s Next: The Radical, Unrealized Potential of Digital Humanities](https://dhdebates.gc.cuny.edu/read/untitled/section/a22aca14-0eb0-4cc6-a622-6fee9428a357)"
* 8/13/2025
  * Lucy Havens, Benjamin Bach, Melissa Terras, Beatrice Alex, "[Investigating the Capabilities and Limitations of Machine Learning for Identifying Bias in English Language Data with Information and Heritage Professionals](https://arxiv.org/abs/2504.00860)"
* 7/30/2025
  * Mar Hicks, "[A Feature Not a Bug](https://www.technologystories.org/a-feature-not-a-bug/)"
  * Mar Hicks, "[De-Brogramming the History of Computing](https://ieeexplore.ieee.org/document/6502624)"
* 7/2/2025
  * Mark Hurst, Emily M. Bender, Alex Hannah. "[Techtonic on The AI Con](https://wfmu.org/archiveplayer/?show=152572&archive=271278)"
* 6/18/2025
 * Emily M. Bender, Alex Hannah, "[On the Very Real Dangers of the Artificial Intelligence Hype Machine](https://lithub.com/on-the-very-real-dangers-of-the-artificial-intelligence-hype-machine/)"
* 5/21/2025
  * Boaz Barak - [I Teach Computer Science, and That is All](https://www.nytimes.com/2025/05/02/opinion/work-school-classroom-politics-harvard.html)
  * Tara McPherson - "[Why Are the Digital Humanities So White? or Thinking the Histories of Race and Computation](https://dhdebates.gc.cuny.edu/read/untitled-88c11800-9446-469b-a3be-3fdb36bfbd1e/section/20df8acd-9ab9-4f35-8a5d-e91aa5f4a0ea)"
* 5/7/2025
  * ProPublica - "[Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)"
  * Wired - "[OpenAI's Sora is Plagued by Sexist, Racist, and Ableist Biases](https://www.wired.com/story/openai-sora-video-generator-bias/)"
* 3/26/2025
  * Jacob Gaboury - "[Becoming NULL: Queer relations in the excluded middle](https://www.womenandperformance.org/bonus-articles-1/jacob-gaboury-28-2)"
* 2/12/2025
  * Torres, "[The Acronym Behind our Wildest AI Dreams and Nightmares](https://www.truthdig.com/articles/the-acronym-behind-our-wildest-ai-dreams-and-nightmares/)"
  * The Atlantic, "[The Rise of Techno-Authoritarianism](https://www.theatlantic.com/magazine/archive/2024/03/facebook-meta-silicon-valley-politics/677168/)" (optional)
* 2/26/2025
  * The Guardian - [Revealed Bias in AI for Benefits](https://www.theguardian.com/society/2024/dec/06/revealed-bias-found-in-ai-system-used-to-detect-uk-benefits)
  * Jiemin Tina Wei - [Amazon Mechanical Turk: The Human Sciences’ Labor Problem](https://read.dukeupress.edu/labor/article-abstract/21/3/6/390482/Amazon-Mechanical-Turk-The-Human-Sciences-Labor?redirectedFrom=fulltext)
* 1/22/2025
  * T.M. Brown (The Atlantic)- "The Technology that Actually Runs our World"
* 11/27/2024
  * Benjamin Shestakofsky - "[Cleaning up data work: Negotiating meaning, morality, and inequality in a tech startup](https://journals.sagepub.com/doi/10.1177/20539517241285372)"
* 11/13/2024
  * Mystery AI Hype Theater 3000 - "[Universities Anxiously Buy into the Hype](https://peertube.dair-institute.org/w/hcYgUjQExZUPQTzpHHNF8z)"
* 10/30/2024
  * Andrew Mallinson - "[Queering AI with Andrew Mallinson](https://www.youtube.com/watch?v=YiJcwFBQgn8&ab_channel=UALCreativeComputingInstitute)"
* 10/16/2024
  * Fulgu & Capraro, "[Surprising Gender Biases in GPT](https://osf.io/preprints/psyarxiv/mp27q)"
* 10/2/2024
  * Webb, Yawhon, Morgan, & Berry, "[Who Owns Black Data? Keynote Address](https://www.youtube.com/watch?v=M6KkrNkKEeQ)"
* 9/18/2024
  * Noble, "[The Power of Algorithms](https://www.jstor.org/stable/j.ctt1pwt9w5.4)," in <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em>: 1-14.
  * Noble, "[Searching for Black Girls](https://www.jstor.org/stable/j.ctt1pwt9w5.6)," in <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em>: 64-109.
* 8/5/2024
  * Nakamura, "[Indigenous Circuits: Navajo Women and the Racialization of Early Electronic Manufacture](https://muse.jhu.edu/article/563663)."
* 7/22/2024
  * Posada, "[Why AI Needs Ethics from Below](https://posada.website/publication/why-ai-needs-ethics-from-below/Posada2021AINow.pdf)."
  * Matheus, Tubaro, & Casili, "[Microwork in Brazil. Who are the workers behind artificial intelligence?](https://hal.science/hal-04140411)."
* 7/8/2024
  * Humberstone, "[I'm a Luddite (and So Can You!)](https://thenib.com/im-a-luddite/)" (revisting)
  * Baker, "[Datasets Have Worldviews](https://pair.withgoogle.com/explorables/dataset-worldviews/)." (revisting)
  * Torres, "[The Acronym Behind our Wildest AI Dreams and Nightmares](https://www.truthdig.com/articles/the-acronym-behind-our-wildest-ai-dreams-and-nightmares/)" (optional)
* 4/1/2024
  * Hofmann, Kalluri, Jurafsky, & King, "[Dialect prejudice predicts AI decisions about people's character, employability, and criminality](https://arxiv.org/abs/2403.00742)."
* 3/11/2024
  * McPherson, "[Why are the Digital Humanities So White? or Thinking the Histories of Race and Computation](https://dhdebates.gc.cuny.edu/read/untitled-88c11800-9446-469b-a3be-3fdb36bfbd1e/section/20df8acd-9ab9-4f35-8a5d-e91aa5f4a0ea)"
* 2/26/2024
  * Matthewson, "[AI Detection Tools Falsely Accuse International Students of Cheating](https://themarkup.org/machine-learning/2023/08/14/ai-detection-tools-falsely-accuse-international-students-of-cheating)"
  * D'Agostino, "[AI Has a Language Diversity Problem](https://www.insidehighered.com/news/tech-innovation/artificial-intelligence/2023/07/10/ai-has-language-diversity-problem)"
* 2/5/2024
  * Akhtar, "[Is Pokemon Go Racist? How the App may be redlining communities of color](https://www.usatoday.com/story/tech/news/2016/08/09/pokemon-go-racist-app-redlining-communities-color-racist-pokestops-gyms/87732734/)"
  * Colley et al., "[The Geography of Pokemon Go: Beneficial and Problematic Effects on Places and Movement](https://brenthecht.com/publications/chi17_geographyofpokemongo.pdf)"
* 11/20/2023
  * (Optional detailed reading) Gebru, Bender, McMillian-Major, & Schmitchell, "[On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)"
  * (Summarizes the above article) Companion, "[Computational Language Models Can Further Environmental Degredation and Language Bias](https://www.dailyuw.com/news/article_f5f735a0-9816-11eb-a5c5-0b22dda3ec6b.html)"
  * Schwab, "[This is Bigger Than just Timnit: How Google Tried to Silence a Critic and Ignited a Movement](https://www.fastcompany.com/90608471/timnit-gebru-google-ai-ethics-equitable-tech-movement)"
* 11/6/2023
  * Noble, "[A Society, Searching](https://www.jstor.org/stable/j.ctt1pwt9w5.5)," in <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em>: 15-63.
* 10/23/2023
  * Baker, "[Datasets Have Worldviews](https://pair.withgoogle.com/explorables/dataset-worldviews/)."
  * Posada, "[Why AI Needs Ethics from Below](https://posada.website/publication/why-ai-needs-ethics-from-below/Posada2021AINow.pdf)"
  * Humberstone, "[I'm a Luddite (and So Can You!)](https://thenib.com/im-a-luddite/)"